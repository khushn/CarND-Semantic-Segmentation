2017-11-09 19:23:21.863247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-09 19:23:21.863520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla M60
major: 5 minor: 2 memoryClockRate (GHz) 1.1775
pciBusID 0000:00:1e.0
Total memory: 7.43GiB
Free memory: 7.35GiB
2017-11-09 19:23:21.863540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-11-09 19:23:21.863547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-11-09 19:23:21.863561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:23:21.950107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:23:21.951222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:23:29.087711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:23:29.098262: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-09 19:23:29.098294: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-09 19:23:29.102907: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3d06590 executing computations on platform Host. Devices:
2017-11-09 19:23:29.102929: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>
2017-11-09 19:23:29.103500: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-09 19:23:29.103525: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-09 19:23:29.106045: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3d4c060 executing computations on platform CUDA. Devices:
2017-11-09 19:23:29.106067: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2
2017-11-09 19:23:29.312076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:23:29.320975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
TensorFlow Version: 1.2.1
Default GPU Device: /gpu:0
Tests Passed
Tests Passed
Tests Passed
Tests Passed
Tests Passed
epoch_i:  0
loss:  1.08722
loss:  1.43708e+13
loss:  179.586
loss:  3.36132
loss:  936.533
loss:  1.9401
loss:  73.0388
loss:  9.97329
loss:  5.5882
loss:  61.1296
loss:  236.162
loss:  53.7966
loss:  41.3472
loss:  100.755
loss:  927.302
loss:  3901.7
loss:  81.4776
loss:  3.3199
loss:  4.29307
loss:  4.85511
loss:  4.31167
loss:  22.6208
loss:  6.81992
loss:  4.99478
loss:  4.47772
loss:  4.19827
loss:  5.82185
loss:  11.6716
loss:  16.7596
loss:  9.5137
loss:  6.53709
loss:  27.1688
loss:  39.7809
loss:  47.7034
loss:  50.2997
loss:  9.37939
loss:  87.9261
loss:  677.306
loss:  19.7212
loss:  22.5828
loss:  13.9485
loss:  12.2253
loss:  5.26824
loss:  4.92801
loss:  107.075
loss:  180.066
loss:  69.8807
loss:  87.1294
loss:  17.0017
loss:  8.63523
loss:  10.7723
loss:  9.27506
loss:  6.13997
loss:  5.22033
loss:  3163.8
loss:  5.46206
loss:  4.93787
loss:  5.01708
loss:  5.14
loss:  5.02831
loss:  5.25743
loss:  4.95762
loss:  5.10572
loss:  5.02029
loss:  13.2858
loss:  4.94969
loss:  4.97
loss:  4.95113
loss:  4.9879
loss:  4.92163
loss:  4.93116
loss:  4.93611
loss:  4.89644
epoch_i:  1
loss:  5.03749
loss:  4.95653
loss:  5.00208
loss:  4.93174
loss:  4.9809
loss:  4.92483
loss:  4.89348
loss:  4.95587
loss:  4.97021
loss:  4.89263
loss:  4.92789
loss:  4.93795
loss:  4.95441
loss:  4.95744
loss:  4.96535
loss:  4.95849
loss:  4.84006
loss:  4.83535
loss:  4.93448
loss:  4.89123
loss:  4.96415
loss:  4.86929
loss:  4.92354
loss:  4.86862
loss:  4.82346
loss:  4.83618
loss:  4.89329
loss:  4.8088
loss:  4.7953
loss:  4.75605
loss:  4.84992
loss:  4.85095
loss:  4.79003
loss:  4.84547
loss:  4.82631
loss:  4.77084
loss:  4.76446
loss:  4.75002
loss:  4.82393
loss:  4.71629
loss:  4.78821
loss:  4.73688
loss:  4.7254
loss:  4.69959
loss:  4.71252
loss:  4.78282
loss:  4.78015
loss:  4.77818
loss:  4.737
loss:  4.70312
loss:  4.71556
loss:  4.68747
loss:  4.69065
loss:  4.76351
loss:  4.64709
loss:  4.75943
loss:  4.74649
loss:  4.66608
loss:  4.69403
loss:  4.71338
loss:  4.67293
loss:  4.70764
loss:  4.69175
loss:  4.71868
loss:  4.69716
loss:  4.65479
loss:  4.67731
loss:  4.66457
loss:  4.70294
loss:  4.60943
loss:  4.64645
loss:  4.68988
loss:  4.79951
epoch_i:  2
loss:  4.61776
loss:  4.68431
loss:  4.64282
loss:  4.64132
loss:  4.7139
loss:  4.57918
loss:  4.65885
loss:  4.57919
loss:  4.70295
loss:  4.6187
loss:  4.62647
loss:  4.64543
loss:  4.67735
loss:  4.63112
loss:  4.60918
loss:  4.6385
loss:  4.69232
loss:  4.54544
loss:  4.6417
loss:  4.6849
loss:  4.5222
loss:  4.50126
loss:  4.66047
loss:  4.59919
loss:  4.55733
loss:  4.55031
loss:  4.55772
loss:  4.56044
loss:  4.58949
loss:  4.57429
loss:  4.57783
loss:  4.58704
loss:  4.53899
loss:  4.61117
loss:  4.55563
loss:  4.52976
loss:  4.5529
loss:  4.59622
loss:  4.52966
loss:  4.53402
loss:  4.55612
loss:  4.51905
loss:  4.5391
loss:  4.55035
loss:  4.48384
loss:  4.49604
loss:  4.5228
loss:  4.52372
loss:  4.57168
loss:  4.4954
loss:  4.45878
loss:  4.56997
loss:  4.52375
loss:  4.48685
loss:  4.5497
loss:  4.4955
loss:  4.47321
loss:  4.49364
loss:  4.5098
loss:  4.50812
loss:  4.58489
loss:  4.48685
loss:  4.57492
loss:  4.44269
loss:  4.53329
loss:  4.47353
loss:  4.49235
loss:  4.47045
loss:  4.5253
loss:  4.57323
loss:  4.58559
loss:  4.47458
loss:  4.8882
epoch_i:  3
loss:  170.568
loss:  4.69488
loss:  4.55111
loss:  4.594
loss:  4.44994
loss:  4.54132
loss:  5.24747
loss:  4.64568
loss:  4.56079
loss:  4.61483
loss:  4.54614
loss:  4.7072
loss:  4.66239
loss:  4.80039
loss:  4.77195
loss:  4.70119
loss:  4.69744
loss:  4.85758
loss:  4.7956
loss:  4.75844
loss:  4.69897
loss:  4.72641
loss:  4.73017
loss:  4.66902
loss:  4.67065
loss:  4.7542
loss:  4.80226
loss:  4.68284
loss:  4.78724
loss:  4.76283
loss:  4.74794
loss:  4.71161
loss:  4.72179
loss:  4.84551
loss:  4.72754
loss:  4.76498
loss:  4.7575
loss:  4.74117
loss:  4.69209
loss:  4.68625
loss:  4.68648
loss:  4.71116
loss:  4.69839
loss:  4.71206
loss:  4.72616
loss:  5.0326
loss:  4.71549
loss:  4.80638
loss:  4.72135
loss:  4.74274
loss:  4.69404
loss:  4.66363
loss:  4.69854
loss:  4.79977
loss:  4.73765
loss:  4.67797
loss:  4.67002
loss:  4.64593
loss:  4.71423
loss:  4.65324
loss:  4.70636
loss:  4.72565
loss:  4.69003
loss:  4.66642
loss:  4.64827
loss:  4.6742
loss:  4.63726
loss:  4.60729
loss:  4.74947
loss:  4.59525
loss:  4.63103
loss:  4.60422
loss:  4.5238
epoch_i:  4
loss:  4.61529
loss:  4.68956
loss:  4.61065
loss:  4.66106
loss:  4.53357
loss:  4.61537
loss:  4.65839
loss:  4.67028
loss:  4.53343
loss:  4.6135
loss:  4.62138
loss:  4.60296
loss:  4.55232
loss:  4.61791
loss:  4.5176
loss:  4.67257
loss:  4.56342
loss:  4.506
loss:  4.61469
loss:  4.59508
loss:  4.57892
loss:  4.58633
loss:  4.6785
loss:  4.59043
loss:  4.58351
loss:  4.57427
loss:  4.53745
loss:  4.51644
loss:  4.60197
loss:  4.60648
loss:  4.56776
loss:  4.57826
loss:  4.55591
loss:  4.5674
loss:  4.54099
loss:  4.56945
loss:  4.55202
loss:  4.53959
loss:  4.5334
loss:  4.52887
loss:  4.53751
loss:  4.5773
loss:  4.52954
loss:  4.48667
loss:  4.57326
loss:  4.57012
loss:  4.60426
loss:  4.54347
loss:  4.48933
loss:  4.57037
loss:  4.53628
loss:  4.51114
loss:  4.55064
loss:  4.54425
loss:  4.46854
loss:  4.51129
loss:  4.54302
loss:  4.50621
loss:  4.48434
loss:  4.499
loss:  4.50207
loss:  4.53285
loss:  4.43325
loss:  4.52862
loss:  4.4866
loss:  4.46937
loss:  4.5123
loss:  4.44539
loss:  4.52873
loss:  4.57234
loss:  4.52065
loss:  4.43181
loss:  4.39198
epoch_i:  5
loss:  4.43233
loss:  4.52333
loss:  4.51244
loss:  4.44466
loss:  4.56648
loss:  4.45962
loss:  4.45472
loss:  4.50138
loss:  4.52794
loss:  4.45179
loss:  4.52727
loss:  4.50018
loss:  4.40332
loss:  4.45585
loss:  4.42825
loss:  4.45781
loss:  4.55562
loss:  4.50626
loss:  4.4577
loss:  4.40137
loss:  4.47781
loss:  4.50464
loss:  4.43847
loss:  4.49525
loss:  4.4856
loss:  4.41532
loss:  4.57488
loss:  4.46029
loss:  4.464
loss:  4.48538
loss:  4.41852
loss:  4.39383
loss:  4.43057
loss:  4.3893
loss:  4.45339
loss:  4.49339
loss:  4.5172
loss:  4.52262
loss:  4.41275
loss:  4.46208
loss:  4.38445
loss:  4.45186
loss:  4.48594
loss:  4.47814
loss:  4.49541
loss:  4.45107
loss:  4.43873
loss:  4.47096
loss:  4.42906
loss:  4.37415
loss:  4.35087
loss:  4.34744
loss:  4.40319
loss:  4.42155
loss:  4.42796
loss:  4.36062
loss:  4.42649
loss:  4.40367
loss:  4.37646
loss:  4.44755
loss:  4.40561
loss:  4.40582
loss:  4.34917
loss:  4.37629
loss:  4.48121
loss:  4.41909
loss:  4.37208
loss:  4.44718
loss:  4.37408
loss:  4.37317
loss:  4.43254
loss:  4.40759
loss:  4.34136
Model saved in file: ./trained_model.ckpt
Training Finished. Saving test images to: ./runs/1510235992.0267217
