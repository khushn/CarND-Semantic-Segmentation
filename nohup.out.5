Traceback (most recent call last):
  File "main.py", line 3, in <module>
    import helper
  File "/home/ubuntu/CarND-Semantic-Segmentation/helper.py", line 116
    for image_file in glob(os.path.join(data_folder, 'image_2', '*.png')):
      ^
IndentationError: expected an indented block
2017-11-09 19:49:57.581900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-09 19:49:57.582179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla M60
major: 5 minor: 2 memoryClockRate (GHz) 1.1775
pciBusID 0000:00:1e.0
Total memory: 7.43GiB
Free memory: 7.35GiB
2017-11-09 19:49:57.582199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-11-09 19:49:57.582206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-11-09 19:49:57.582221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:49:57.672180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:49:57.673394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:50:05.025136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:50:05.036508: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-09 19:50:05.036530: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-09 19:50:05.041922: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3b1da60 executing computations on platform Host. Devices:
2017-11-09 19:50:05.041940: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>
2017-11-09 19:50:05.042508: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-09 19:50:05.042526: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-09 19:50:05.044167: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3ba9800 executing computations on platform CUDA. Devices:
2017-11-09 19:50:05.044183: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2
2017-11-09 19:50:05.249352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-09 19:50:05.258344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
TensorFlow Version: 1.2.1
Default GPU Device: /gpu:0
Tests Passed
Tests Passed
Tests Passed
Tests Passed
Tests Passed
epoch_i:  0
loss:  1.08989
loss:  1.31434
loss:  1.1047
loss:  1.01577
loss:  1.07589
loss:  0.978741
loss:  0.962042
loss:  0.944239
loss:  0.920646
loss:  1.47563
loss:  0.904328
loss:  0.918154
loss:  0.906951
loss:  0.890236
loss:  0.903776
loss:  0.889868
loss:  0.886127
loss:  0.877719
loss:  0.864039
loss:  0.851537
loss:  0.877981
loss:  0.839009
loss:  0.837082
loss:  0.827127
loss:  0.816348
loss:  0.805846
loss:  0.793873
loss:  0.789945
loss:  0.782166
loss:  0.77045
loss:  0.755611
loss:  0.744574
loss:  0.729283
loss:  0.707307
loss:  0.694377
loss:  0.685862
loss:  0.60807
loss:  0.578861
loss:  0.645553
loss:  0.595544
loss:  0.53114
loss:  0.473188
loss:  0.559857
loss:  0.485773
loss:  0.452823
loss:  0.469753
loss:  0.459247
loss:  0.478907
loss:  0.403283
loss:  0.416794
loss:  0.436045
loss:  0.450203
loss:  0.357802
loss:  0.369484
loss:  0.386034
loss:  0.362682
loss:  0.412825
loss:  0.356273
loss:  0.343951
loss:  0.426634
loss:  0.358608
loss:  0.364246
loss:  0.33875
loss:  0.444767
loss:  0.357423
loss:  0.354237
loss:  0.362427
loss:  0.360655
loss:  0.336676
loss:  0.317397
loss:  0.348574
loss:  0.468344
loss:  0.462863
epoch_i:  1
loss:  0.316448
loss:  0.337994
loss:  0.304026
loss:  0.316293
loss:  0.309948
loss:  0.313321
loss:  4.20304
loss:  0.402265
loss:  0.476069
loss:  0.649501
loss:  0.575629
loss:  0.541338
loss:  0.534646
loss:  0.545719
loss:  0.564945
loss:  0.47186
loss:  0.555463
loss:  0.507285
loss:  0.506974
loss:  0.506821
loss:  0.487292
loss:  0.496224
loss:  0.484644
loss:  0.503783
loss:  0.481728
loss:  0.455659
loss:  0.429298
loss:  0.50901
loss:  0.420613
loss:  0.436871
loss:  0.437874
loss:  0.413792
loss:  0.410703
loss:  0.414424
loss:  0.381804
loss:  0.385476
loss:  0.475751
loss:  0.397835
loss:  0.368728
loss:  0.407632
loss:  0.372872
loss:  0.375087
loss:  0.388703
loss:  0.365981
loss:  0.381261
loss:  0.391342
loss:  0.355846
loss:  0.449533
loss:  0.339168
loss:  0.381298
loss:  0.355384
loss:  0.350572
loss:  0.356121
loss:  0.296327
loss:  0.41999
loss:  0.371692
loss:  0.328369
loss:  0.331502
loss:  0.342987
loss:  0.344568
loss:  0.3044
loss:  0.298772
loss:  0.348398
loss:  0.32238
loss:  0.287653
loss:  0.332898
loss:  0.287719
loss:  0.318695
loss:  0.352829
loss:  0.287341
loss:  0.311504
loss:  0.314736
loss:  0.253483
epoch_i:  2
loss:  0.335324
loss:  0.263275
loss:  0.280493
loss:  0.306338
loss:  0.365984
loss:  0.277724
loss:  0.308978
loss:  0.276517
loss:  0.289024
loss:  0.363945
loss:  0.289422
loss:  0.262472
loss:  0.263061
loss:  0.313369
loss:  0.295153
loss:  0.351796
loss:  0.342551
loss:  0.293455
loss:  0.311453
loss:  0.25348
loss:  0.25625
loss:  0.326399
loss:  0.305844
loss:  0.306737
loss:  0.331341
loss:  0.333046
loss:  0.276137
loss:  0.299315
loss:  0.280651
loss:  0.324608
loss:  0.311094
loss:  0.297196
loss:  0.292157
loss:  0.243784
loss:  0.285611
loss:  0.244268
loss:  0.272215
loss:  0.241702
loss:  0.27633
loss:  0.29841
loss:  0.263072
loss:  0.317007
loss:  0.275235
loss:  0.259041
loss:  0.258843
loss:  0.235209
loss:  0.26895
loss:  0.221397
loss:  0.243006
loss:  0.304173
loss:  0.293272
loss:  0.245397
loss:  0.248786
loss:  0.266822
loss:  0.294152
loss:  0.240304
loss:  0.233535
loss:  0.235092
loss:  0.28664
loss:  0.396483
loss:  0.242925
loss:  0.280093
loss:  0.245796
loss:  0.278868
loss:  0.257758
loss:  0.261322
loss:  0.263233
loss:  0.296672
loss:  0.356331
loss:  0.272465
loss:  0.249919
loss:  0.237457
loss:  0.27879
epoch_i:  3
loss:  0.25012
loss:  0.391358
loss:  0.242481
loss:  0.228874
loss:  0.276533
loss:  0.269862
loss:  0.275059
loss:  0.269111
loss:  0.270447
loss:  0.253186
loss:  0.259313
loss:  0.254416
loss:  0.249176
loss:  0.257921
loss:  0.269956
loss:  0.248443
loss:  0.284065
loss:  0.249496
loss:  0.277864
loss:  0.284555
loss:  0.225254
loss:  0.215034
loss:  0.262127
loss:  0.266695
loss:  0.21295
loss:  0.228624
loss:  0.234686
loss:  0.259933
loss:  0.266086
loss:  0.255231
loss:  0.239501
loss:  0.260325
loss:  0.228779
loss:  0.242504
loss:  0.217777
loss:  0.2651
loss:  0.289454
loss:  0.264464
loss:  0.225256
loss:  0.242517
loss:  0.215189
loss:  0.266058
loss:  0.270652
loss:  0.190811
loss:  0.255481
loss:  0.36851
loss:  0.273472
loss:  0.249812
loss:  0.251793
loss:  0.270238
loss:  0.238574
loss:  0.260198
loss:  0.224328
loss:  0.222913
loss:  0.276425
loss:  0.272711
loss:  0.247138
loss:  0.225081
loss:  0.227943
loss:  0.192831
loss:  0.303551
loss:  0.244288
loss:  0.215103
loss:  0.212514
loss:  0.419832
loss:  0.252301
loss:  0.238212
loss:  0.258477
loss:  0.269909
loss:  0.22393
loss:  0.207744
loss:  0.20458
loss:  0.272479
epoch_i:  4
loss:  0.342917
loss:  0.257354
loss:  0.196678
loss:  0.240618
loss:  0.240093
loss:  0.235149
loss:  0.241527
loss:  0.272192
loss:  0.240413
loss:  0.209399
loss:  0.203224
loss:  0.251897
loss:  0.275321
loss:  0.288832
loss:  0.202194
loss:  0.255905
loss:  0.249407
loss:  0.213728
loss:  0.232685
loss:  0.212082
loss:  0.205324
loss:  0.204995
loss:  0.238044
loss:  0.205644
loss:  0.277481
loss:  0.207649
loss:  0.208738
loss:  0.197947
loss:  0.244519
loss:  0.216845
loss:  0.21497
loss:  0.214408
loss:  0.209058
loss:  0.249159
loss:  0.181963
loss:  0.192702
loss:  0.260807
loss:  0.200951
loss:  0.24039
loss:  0.200334
loss:  0.204921
loss:  0.184548
loss:  0.178535
loss:  0.246335
loss:  0.233709
loss:  0.208447
loss:  0.257899
loss:  0.34926
loss:  0.23174
loss:  0.250562
loss:  0.254186
loss:  0.242306
loss:  0.221893
loss:  0.219278
loss:  0.192265
loss:  0.248533
loss:  0.194338
loss:  0.263591
loss:  0.239136
loss:  0.294607
loss:  0.225063
loss:  0.192208
loss:  0.225028
loss:  0.193585
loss:  0.244063
loss:  0.179457
loss:  0.191279
loss:  0.183884
loss:  0.170508
loss:  0.171035
loss:  0.153387
loss:  0.229067
loss:  0.390013
epoch_i:  5
loss:  0.211785
loss:  0.24282
loss:  0.252002
loss:  0.20013
loss:  0.216903
loss:  0.215478
loss:  0.191089
loss:  0.209817
loss:  0.185379
loss:  0.206929
loss:  0.225494
loss:  0.20304
loss:  0.208576
loss:  0.201053
loss:  0.187349
loss:  0.208742
loss:  0.211011
loss:  0.193658
loss:  0.243391
loss:  0.201193
loss:  0.185612
loss:  0.205525
loss:  0.217325
loss:  0.211321
loss:  0.185112
loss:  0.201226
loss:  0.225418
loss:  0.179876
loss:  0.165126
loss:  0.19341
loss:  0.220103
loss:  0.204688
loss:  0.210128
loss:  0.188988
loss:  0.215422
loss:  0.211233
loss:  0.222529
loss:  0.162581
loss:  0.176261
loss:  0.151934
loss:  0.179535
loss:  0.186651
loss:  0.231019
loss:  0.153487
loss:  0.154948
loss:  0.171675
loss:  0.187362
loss:  0.181288
loss:  0.214932
loss:  0.215382
loss:  0.191598
loss:  0.223055
loss:  0.236427
loss:  0.17393
loss:  0.194786
loss:  0.227094
loss:  0.229562
loss:  0.205475
loss:  0.168448
loss:  0.228037
loss:  0.231257
loss:  0.222546
loss:  0.188307
loss:  0.217159
loss:  0.220316
loss:  0.240933
loss:  0.198415
loss:  0.235615
loss:  0.178046
loss:  0.214233
loss:  0.20947
loss:  0.194281
loss:  0.125085
Model saved in file: ./trained_model.ckpt
Training Finished. Saving test images to: ./runs/1510237677.9563243
