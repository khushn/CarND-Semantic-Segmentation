2017-11-10 18:53:15.838148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-10 18:53:15.838405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla M60
major: 5 minor: 2 memoryClockRate (GHz) 1.1775
pciBusID 0000:00:1e.0
Total memory: 7.43GiB
Free memory: 7.35GiB
2017-11-10 18:53:15.838423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-11-10 18:53:15.838430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-11-10 18:53:15.838441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 18:53:15.923809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 18:53:15.925051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 18:53:23.375751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 18:53:23.386333: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-10 18:53:23.386353: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-10 18:53:23.390641: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3f99a10 executing computations on platform Host. Devices:
2017-11-10 18:53:23.390657: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>
2017-11-10 18:53:23.391165: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-10 18:53:23.391181: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-10 18:53:23.394072: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x403cfc0 executing computations on platform CUDA. Devices:
2017-11-10 18:53:23.394088: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2
2017-11-10 18:53:23.591732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 18:53:23.600448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
TensorFlow Version: 1.2.1
Default GPU Device: /gpu:0
Tests Passed
Tests Passed
Tests Passed
Tests Passed
Tests Passed
epoch_i:  0
loss:  1.08704
loss:  1.0951
loss:  5.80677
loss:  1.00835
loss:  1.00575
loss:  0.961423
loss:  0.944785
loss:  0.930084
loss:  0.921782
loss:  0.906653
loss:  0.898198
loss:  0.889433
loss:  0.886492
loss:  0.877041
loss:  0.874613
loss:  0.864577
loss:  0.860768
loss:  0.859491
loss:  0.853894
loss:  0.849637
loss:  0.848503
loss:  0.845523
loss:  0.843293
loss:  0.841154
loss:  0.836821
loss:  0.833016
loss:  0.829818
loss:  0.826486
loss:  0.82206
loss:  0.825848
loss:  0.818008
loss:  0.81511
loss:  0.808989
loss:  0.811318
loss:  0.800887
loss:  0.810052
loss:  0.804608
loss:  0.797288
loss:  0.795377
loss:  0.788288
loss:  0.773734
loss:  0.797185
loss:  0.788071
loss:  0.790226
loss:  0.76466
loss:  0.771676
loss:  0.745287
loss:  0.733752
loss:  0.76988
loss:  0.746413
loss:  0.741882
loss:  0.715794
loss:  0.726912
loss:  0.684904
loss:  0.694833
loss:  0.937003
loss:  0.682164
loss:  0.70004
loss:  0.694034
loss:  0.657451
loss:  0.683423
loss:  0.619904
loss:  0.628137
loss:  0.618774
loss:  0.55965
loss:  0.666682
loss:  0.612469
loss:  0.608005
loss:  0.636294
loss:  0.529272
loss:  0.613512
loss:  0.508401
loss:  0.456141
epoch_i:  1
loss:  0.485774
loss:  0.529208
loss:  0.494582
loss:  0.494284
loss:  0.452162
loss:  0.465477
loss:  0.488695
loss:  0.462963
loss:  0.417693
loss:  0.478463
loss:  0.453917
loss:  0.411099
loss:  0.313406
loss:  2.24257
loss:  0.459799
loss:  0.573867
loss:  0.67798
loss:  0.579656
loss:  1.11455
loss:  0.665801
loss:  0.618805
loss:  0.691572
loss:  0.678287
loss:  0.690419
loss:  0.634703
loss:  0.564006
loss:  0.568944
loss:  0.539366
loss:  0.520178
loss:  0.535193
loss:  0.550638
loss:  0.497465
loss:  0.65616
loss:  0.511037
loss:  0.527145
loss:  0.53609
loss:  0.520771
loss:  0.486654
loss:  0.476468
loss:  0.553482
loss:  0.486437
loss:  0.502262
loss:  0.49531
loss:  0.47045
loss:  0.446898
loss:  0.486751
loss:  0.482238
loss:  0.465294
loss:  0.434825
loss:  0.500565
loss:  0.425516
loss:  0.401588
loss:  0.462184
loss:  0.389315
loss:  0.452797
loss:  0.428861
loss:  0.40039
loss:  0.389857
loss:  0.501137
loss:  0.422551
loss:  0.403606
loss:  0.397816
loss:  0.404686
loss:  0.506974
loss:  0.445681
loss:  0.464829
loss:  0.454462
loss:  0.408296
loss:  0.4111
loss:  0.437028
loss:  0.479108
loss:  0.388871
loss:  0.389869
epoch_i:  2
loss:  0.387859
loss:  0.442244
loss:  0.352993
loss:  0.356532
loss:  0.349246
loss:  0.35541
loss:  0.415703
loss:  0.352333
loss:  0.3528
loss:  0.390937
loss:  0.342039
loss:  0.404066
loss:  0.32548
loss:  0.35575
loss:  0.361965
loss:  0.356509
loss:  0.368055
loss:  0.415489
loss:  0.4251
loss:  0.40021
loss:  0.390374
loss:  0.372319
loss:  0.382373
loss:  0.476514
loss:  0.399293
loss:  0.376652
loss:  0.343271
loss:  0.303096
loss:  0.352145
loss:  0.639334
loss:  0.390645
loss:  0.35255
loss:  0.441095
loss:  0.411985
loss:  0.410331
loss:  0.435491
loss:  0.418421
loss:  0.391524
loss:  0.361059
loss:  0.349372
loss:  0.379695
loss:  0.435025
loss:  0.391329
loss:  0.374417
loss:  0.410869
loss:  0.364794
loss:  0.374004
loss:  0.37396
loss:  0.353518
loss:  0.391254
loss:  0.364887
loss:  0.408471
loss:  0.339214
loss:  0.316711
loss:  0.342809
loss:  0.312826
loss:  0.356274
loss:  0.369341
loss:  0.3935
loss:  0.368885
loss:  0.409823
loss:  0.379434
loss:  0.401425
loss:  0.380496
loss:  0.36641
loss:  0.322087
loss:  0.390186
loss:  0.308451
loss:  0.301607
loss:  0.357533
loss:  0.342663
loss:  0.343062
loss:  0.281293
epoch_i:  3
loss:  0.372721
loss:  0.458637
loss:  0.42169
loss:  0.339342
loss:  0.403783
loss:  0.360297
loss:  0.381658
loss:  0.372252
loss:  0.341044
loss:  0.376387
loss:  0.39814
loss:  0.324198
loss:  0.309901
loss:  0.342465
loss:  0.364354
loss:  0.319198
loss:  0.30623
loss:  0.311221
loss:  0.346516
loss:  0.282653
loss:  0.393605
loss:  0.436764
loss:  0.381823
loss:  0.358396
loss:  0.324811
loss:  0.426168
loss:  0.350515
loss:  0.33707
loss:  0.310296
loss:  0.325683
loss:  0.280774
loss:  0.310352
loss:  0.371428
loss:  0.375554
loss:  0.309384
loss:  0.332324
loss:  0.326067
loss:  0.33034
loss:  0.317428
loss:  0.318061
loss:  0.362685
loss:  0.283792
loss:  0.282289
loss:  0.315865
loss:  0.397831
loss:  0.346075
loss:  0.303965
loss:  0.392559
loss:  0.304745
loss:  0.313878
loss:  0.304954
loss:  0.332655
loss:  0.284443
loss:  0.306579
loss:  0.346673
loss:  0.341251
loss:  0.286953
loss:  0.280857
loss:  0.302136
loss:  0.28563
loss:  0.28285
loss:  0.296426
loss:  0.34549
loss:  0.743925
loss:  0.316779
loss:  0.371005
loss:  0.446938
loss:  0.44038
loss:  0.483929
loss:  0.473107
loss:  0.455417
loss:  0.428072
loss:  0.411208
epoch_i:  4
loss:  0.427855
loss:  0.421698
loss:  0.394457
loss:  0.389921
loss:  0.401895
loss:  0.388689
loss:  0.386875
loss:  0.356419
loss:  0.545577
loss:  0.385459
loss:  0.429115
loss:  0.463078
loss:  0.412469
loss:  0.446914
loss:  0.406913
loss:  0.436848
loss:  0.391387
loss:  0.361202
loss:  0.61233
loss:  0.382414
loss:  0.410077
loss:  0.420814
loss:  0.413876
loss:  0.407001
loss:  0.395476
loss:  0.38104
loss:  0.40232
loss:  0.458909
loss:  0.384265
loss:  0.373936
loss:  0.406491
loss:  0.343623
loss:  0.382926
loss:  0.345722
loss:  0.314929
loss:  0.313203
loss:  0.350571
loss:  0.364716
loss:  0.332109
loss:  0.31376
loss:  0.312365
loss:  0.296212
loss:  0.461573
loss:  0.370996
loss:  0.386359
loss:  0.34031
loss:  0.372667
loss:  0.371392
loss:  0.331431
loss:  0.349351
loss:  0.356174
loss:  0.358723
loss:  0.304687
loss:  0.333862
loss:  0.297836
loss:  0.335448
loss:  0.501076
loss:  0.299969
loss:  0.310445
loss:  0.332689
loss:  0.38384
loss:  0.324037
loss:  0.303813
loss:  0.348592
loss:  0.340174
loss:  0.377019
loss:  0.329255
loss:  0.275833
loss:  0.287732
loss:  0.344789
loss:  0.268866
loss:  0.366407
loss:  0.257801
epoch_i:  5
loss:  0.337782
loss:  0.368753
loss:  0.319281
loss:  0.309584
loss:  0.323834
loss:  0.299626
loss:  0.35795
loss:  0.308056
loss:  0.300964
loss:  0.302755
loss:  0.35312
loss:  0.316305
loss:  0.323187
loss:  0.318331
loss:  0.364283
loss:  0.322788
loss:  0.342364
loss:  0.362335
loss:  0.335122
loss:  0.270697
loss:  0.302073
loss:  0.306416
loss:  0.421871
loss:  0.350819
loss:  0.318107
loss:  0.300189
loss:  0.306357
loss:  0.37128
loss:  0.280617
loss:  0.33251
loss:  0.296179
loss:  0.354033
loss:  0.364566
loss:  0.31056
loss:  0.28766
loss:  0.303748
loss:  0.326417
loss:  0.29574
loss:  0.290908
loss:  0.279119
loss:  0.266049
loss:  0.364055
loss:  0.510424
loss:  0.353109
loss:  0.326031
loss:  0.374826
loss:  0.368957
loss:  0.319614
loss:  0.337426
loss:  0.35051
loss:  0.332862
loss:  0.326324
loss:  0.346253
loss:  0.330363
loss:  0.297793
loss:  0.319239
loss:  0.284393
loss:  0.266802
loss:  0.246112
loss:  0.239154
loss:  0.218752
loss:  0.319322
loss:  0.424951
loss:  0.258782
loss:  0.276647
loss:  0.274467
loss:  0.331444
loss:  0.311362
loss:  0.317736
loss:  0.309355
loss:  0.298467
loss:  0.347881
loss:  0.336461
epoch_i:  6
loss:  0.255325
loss:  0.339266
loss:  0.321683
loss:  0.30721
loss:  0.317841
loss:  0.290275
loss:  0.294819
loss:  0.364479
loss:  0.276531
loss:  0.317438
loss:  0.323086
loss:  0.313227
loss:  0.315717
loss:  0.295155
loss:  0.271616
loss:  0.298774
loss:  0.303195
loss:  0.418274
loss:  0.368793
loss:  0.308892
loss:  0.302154
loss:  0.346718
loss:  0.365977
loss:  0.284504
loss:  0.365404
loss:  0.299524
loss:  0.271332
loss:  0.320759
loss:  0.303928
loss:  0.355142
loss:  0.271418
loss:  0.282763
loss:  0.249647
loss:  0.381793
loss:  0.375552
loss:  0.277243
loss:  0.273473
loss:  0.286716
loss:  0.258825
loss:  0.243168
loss:  0.310871
loss:  0.264413
loss:  0.292444
loss:  0.294056
loss:  0.352074
loss:  0.259397
loss:  0.34205
loss:  0.298095
loss:  0.28129
loss:  0.253521
loss:  0.337978
loss:  0.274055
loss:  0.316353
loss:  0.283564
loss:  0.396415
loss:  0.288362
loss:  0.28121
loss:  0.331268
loss:  0.26469
loss:  0.30743
loss:  0.335724
loss:  0.258425
loss:  0.274647
loss:  0.345006
loss:  0.23431
loss:  0.277278
loss:  0.225426
loss:  0.373655
loss:  0.304462
loss:  0.322467
loss:  0.303568
loss:  0.304198
loss:  0.45613
epoch_i:  7
loss:  0.313262
loss:  0.32329
loss:  0.273462
loss:  0.321679
loss:  0.288287
loss:  0.305381
loss:  0.312407
loss:  0.27488
loss:  0.273775
loss:  0.277921
loss:  0.401115
loss:  0.336393
loss:  0.274446
loss:  0.281379
loss:  0.320398
loss:  0.28929
loss:  0.302701
loss:  0.296879
loss:  0.311786
loss:  0.247528
loss:  0.253321
loss:  0.239997
loss:  0.284724
loss:  0.329502
loss:  0.228125
loss:  0.400141
loss:  0.317697
loss:  0.283413
loss:  0.249052
loss:  0.263383
loss:  0.266991
loss:  0.31995
loss:  0.250555
loss:  0.286678
loss:  0.301123
loss:  0.312227
loss:  0.260819
loss:  0.369093
loss:  0.303024
loss:  0.315667
loss:  0.253541
loss:  0.330268
loss:  0.29198
loss:  0.359853
loss:  0.322266
loss:  0.263701
loss:  0.304542
loss:  0.2741
loss:  0.269111
loss:  0.302586
loss:  0.329455
loss:  0.319527
loss:  0.266897
loss:  0.238608
loss:  0.249783
loss:  0.237968
loss:  0.236882
loss:  0.303336
loss:  0.426734
loss:  0.22289
loss:  0.27413
loss:  0.292488
loss:  0.289437
loss:  0.278952
loss:  0.292263
loss:  0.265935
loss:  0.24978
loss:  0.328199
loss:  0.246661
loss:  0.355658
loss:  0.334235
loss:  0.271031
loss:  0.27722
epoch_i:  8
loss:  0.251005
loss:  0.308781
loss:  0.290596
loss:  0.327482
loss:  0.37672
loss:  0.275466
loss:  0.29439
loss:  0.280797
loss:  0.239113
loss:  0.248805
loss:  0.244421
loss:  0.371127
loss:  0.319921
loss:  0.299396
loss:  0.334645
loss:  0.297984
loss:  0.299242
loss:  0.27812
loss:  0.300941
loss:  0.281451
loss:  0.332403
loss:  0.249102
loss:  0.263449
loss:  0.278088
loss:  0.287276
loss:  0.246207
loss:  0.276899
loss:  0.251474
loss:  0.256901
loss:  0.25937
loss:  0.331164
loss:  0.242165
loss:  0.292306
loss:  0.239977
loss:  0.32119
loss:  0.269519
loss:  1.9667
loss:  0.286667
loss:  0.384733
loss:  0.569747
loss:  0.31941
loss:  0.399025
loss:  0.375213
loss:  0.39131
loss:  0.37523
loss:  0.38902
loss:  0.369717
loss:  0.433164
loss:  0.427625
loss:  0.38909
loss:  0.328833
loss:  0.313783
loss:  0.385767
loss:  0.469792
loss:  0.334809
loss:  0.398904
loss:  0.526106
loss:  0.362601
loss:  0.381204
loss:  0.400374
loss:  0.415692
loss:  0.387757
loss:  0.380655
loss:  0.384467
loss:  0.370029
loss:  0.388624
loss:  0.285981
loss:  0.331233
loss:  0.362776
loss:  0.413088
loss:  0.338354
loss:  0.323946
loss:  0.322546
epoch_i:  9
loss:  0.410391
loss:  0.391975
loss:  0.416961
loss:  0.352835
loss:  0.392768
loss:  0.376555
loss:  0.316732
loss:  0.356661
loss:  0.30422
loss:  0.323003
loss:  0.312692
loss:  0.405
loss:  0.304203
loss:  0.354882
loss:  0.306607
loss:  0.292927
loss:  0.372257
loss:  0.361827
loss:  0.297059
loss:  0.336866
loss:  0.299186
loss:  0.312714
loss:  0.285259
loss:  0.320118
loss:  0.270149
loss:  0.323759
loss:  0.273214
loss:  0.287549
loss:  0.457015
loss:  0.311909
loss:  0.310566
loss:  0.270461
loss:  0.306121
loss:  0.29025
loss:  0.356552
loss:  0.308759
loss:  0.29235
loss:  0.302817
loss:  0.308481
loss:  0.33974
loss:  0.334915
loss:  0.27295
loss:  0.281012
loss:  0.365199
loss:  0.274775
loss:  0.256108
loss:  0.305212
loss:  0.302837
loss:  0.272652
loss:  0.294117
loss:  0.317738
loss:  0.275844
loss:  0.364695
loss:  0.294673
loss:  0.259477
loss:  0.295812
loss:  0.364519
loss:  0.360431
loss:  0.28214
loss:  0.27113
loss:  0.335665
loss:  0.263283
loss:  0.375444
loss:  0.341413
loss:  0.366837
loss:  0.341048
loss:  0.31392
loss:  0.367451
loss:  0.330669
loss:  0.328816
loss:  0.324585
loss:  0.273227
loss:  0.25746
Model saved in file: ./trained_model.ckpt
Training Finished. Saving test images to: ./runs/1510320918.0049462
