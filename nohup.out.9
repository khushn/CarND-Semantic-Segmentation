2017-11-10 19:24:16.569043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-10 19:24:16.569300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla M60
major: 5 minor: 2 memoryClockRate (GHz) 1.1775
pciBusID 0000:00:1e.0
Total memory: 7.43GiB
Free memory: 7.35GiB
2017-11-10 19:24:16.569316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-11-10 19:24:16.569322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-11-10 19:24:16.569334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 19:24:16.654725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 19:24:16.655855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 19:24:23.921068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 19:24:23.932095: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-10 19:24:23.932119: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-10 19:24:23.936390: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x39d3c90 executing computations on platform Host. Devices:
2017-11-10 19:24:23.936409: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>
2017-11-10 19:24:23.936920: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-11-10 19:24:23.936935: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-11-10 19:24:23.939438: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x3a70ef0 executing computations on platform CUDA. Devices:
2017-11-10 19:24:23.939452: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2
2017-11-10 19:24:24.140674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
2017-11-10 19:24:24.149491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0)
TensorFlow Version: 1.2.1
Default GPU Device: /gpu:0
Tests Passed
Tests Passed
Tests Passed
Tests Passed
Tests Passed
epoch_i:  0
loss:  1.08243
loss:  1.34303
loss:  1.01597
loss:  1.02658
loss:  0.966019
loss:  0.939931
loss:  2.03567
loss:  0.897361
loss:  0.910484
loss:  0.915452
loss:  0.915198
loss:  0.901029
loss:  0.898991
loss:  0.888774
loss:  0.880187
loss:  0.87201
loss:  0.874505
loss:  0.859287
loss:  0.879468
loss:  0.852216
loss:  0.854832
loss:  0.847068
loss:  0.844989
loss:  0.84644
loss:  0.828223
loss:  0.83086
loss:  0.815238
loss:  0.79871
loss:  0.784829
loss:  0.7619
loss:  0.718989
loss:  0.688215
loss:  0.709051
loss:  0.665688
loss:  0.678635
loss:  0.625797
loss:  0.676569
loss:  0.63875
loss:  0.711837
loss:  0.583569
loss:  0.657378
loss:  0.598769
loss:  0.590881
loss:  0.528041
loss:  0.56271
loss:  0.458924
loss:  0.561193
loss:  0.425902
loss:  0.545905
loss:  0.520291
loss:  0.453603
loss:  0.443838
loss:  0.402188
loss:  0.419711
loss:  0.632069
loss:  0.562093
loss:  0.676386
loss:  0.458048
loss:  0.503657
loss:  0.484952
loss:  0.524165
loss:  0.468532
loss:  0.451681
loss:  0.361876
loss:  0.486264
loss:  0.482082
loss:  0.370486
loss:  0.471486
loss:  0.43746
loss:  0.42347
loss:  0.363112
loss:  0.348236
loss:  0.401825
loss:  0.402243
loss:  1.14565
loss:  0.383651
loss:  0.464295
loss:  0.380388
loss:  0.436401
loss:  0.409821
loss:  0.39086
loss:  0.424715
loss:  0.450202
loss:  0.364571
loss:  0.395172
loss:  0.388512
loss:  0.417023
loss:  0.439946
loss:  0.408203
loss:  0.35888
loss:  0.326642
loss:  0.383366
loss:  0.438911
loss:  1.78696
loss:  0.382029
loss:  0.411603
loss:  0.418984
loss:  0.465131
loss:  0.414587
loss:  0.470577
loss:  0.534807
loss:  0.405596
loss:  0.382335
loss:  0.381765
loss:  0.408187
loss:  0.398838
loss:  0.707327
loss:  0.40473
loss:  0.532782
loss:  0.46724
loss:  0.433439
loss:  0.481332
loss:  0.438142
loss:  0.349089
loss:  0.547837
loss:  0.40902
loss:  0.361487
loss:  0.702012
loss:  0.359838
loss:  0.410157
loss:  0.447722
loss:  0.450547
loss:  0.388779
loss:  0.389697
loss:  0.336548
loss:  0.446474
loss:  0.425354
loss:  0.399809
loss:  0.328874
loss:  0.448513
loss:  0.308198
loss:  0.331141
loss:  0.423219
loss:  0.298062
loss:  0.540884
loss:  0.305936
loss:  0.432085
loss:  0.385151
loss:  0.384242
loss:  0.418092
loss:  0.421792
loss:  0.419778
loss:  0.357775
loss:  0.363222
loss:  0.331404
epoch_i:  1
loss:  0.35962
loss:  0.453233
loss:  0.385228
loss:  0.417617
loss:  0.399596
loss:  0.329393
loss:  0.380876
loss:  0.370315
loss:  0.360486
loss:  0.469431
loss:  0.339056
loss:  0.340124
loss:  0.408924
loss:  0.377665
loss:  0.304422
loss:  0.400739
loss:  0.307639
loss:  0.300351
loss:  0.272715
loss:  0.303068
loss:  0.339152
loss:  0.331579
loss:  0.359574
loss:  0.310659
loss:  0.432556
loss:  0.295989
loss:  0.283974
loss:  0.296666
loss:  0.31173
loss:  0.275099
loss:  0.288408
loss:  0.319286
loss:  0.341581
loss:  0.96938
loss:  0.303805
loss:  0.305994
loss:  0.44378
loss:  0.511743
loss:  0.452654
loss:  0.342374
loss:  0.449402
loss:  0.369538
loss:  0.364021
loss:  0.407163
loss:  0.363567
loss:  0.352092
loss:  0.36862
loss:  0.37931
loss:  0.475592
loss:  0.339534
loss:  0.341941
loss:  0.336976
loss:  0.446878
loss:  0.371459
loss:  0.343092
loss:  0.327489
loss:  0.299284
loss:  0.346999
loss:  0.392919
loss:  0.372949
loss:  0.324088
loss:  0.381373
loss:  0.342752
loss:  0.327407
loss:  0.350792
loss:  0.350156
loss:  0.438954
loss:  0.442936
loss:  0.434096
loss:  0.347622
loss:  0.368671
loss:  0.396851
loss:  0.366244
loss:  0.369311
loss:  0.372324
loss:  0.40779
loss:  0.461193
loss:  0.375248
loss:  0.37273
loss:  0.265303
loss:  0.402508
loss:  0.353269
loss:  0.357576
loss:  0.320099
loss:  0.276231
loss:  0.247672
loss:  0.311997
loss:  0.361699
loss:  0.287861
loss:  0.477051
loss:  0.397907
loss:  0.262338
loss:  0.331673
loss:  0.406305
loss:  0.403056
loss:  0.34971
loss:  0.322092
loss:  0.397471
loss:  0.344663
loss:  0.323865
loss:  0.428262
loss:  0.343314
loss:  0.426142
loss:  0.339184
loss:  0.333549
loss:  0.294867
loss:  0.305489
loss:  0.289035
loss:  0.292141
loss:  0.282248
loss:  0.346611
loss:  0.518384
loss:  0.289726
loss:  0.290654
loss:  0.335831
loss:  0.320215
loss:  0.241948
loss:  0.240565
loss:  0.291463
loss:  0.390088
loss:  0.318344
loss:  0.330649
loss:  0.377214
loss:  0.281013
loss:  0.278447
loss:  0.385961
loss:  0.414943
loss:  0.273435
loss:  0.35858
loss:  0.420062
loss:  0.359613
loss:  0.270427
loss:  0.347171
loss:  0.243733
loss:  0.345691
loss:  0.377225
loss:  0.374204
loss:  0.308717
loss:  0.275179
loss:  0.306026
loss:  0.250031
loss:  0.330698
loss:  0.41672
loss:  0.290027
loss:  0.273634
epoch_i:  2
loss:  0.26193
loss:  0.34242
loss:  0.265206
loss:  0.358333
loss:  0.38593
loss:  0.230646
loss:  0.258171
loss:  0.276634
loss:  0.265218
loss:  0.307548
loss:  0.279073
loss:  0.321673
loss:  0.233839
loss:  0.340176
loss:  0.496612
loss:  0.497125
loss:  0.280254
loss:  0.411171
loss:  0.290687
loss:  0.299237
loss:  0.38392
loss:  0.398598
loss:  0.335719
loss:  0.348654
loss:  0.291965
loss:  0.315708
loss:  0.254142
loss:  0.391126
loss:  0.325415
loss:  0.259181
loss:  0.301839
loss:  0.335959
loss:  0.334655
loss:  0.240757
loss:  0.231646
loss:  0.290709
loss:  0.229139
loss:  0.342518
loss:  0.299413
loss:  0.320051
loss:  0.246489
loss:  0.345403
loss:  0.274815
loss:  0.243585
loss:  0.430444
loss:  0.830054
loss:  0.295927
loss:  0.299662
loss:  0.285156
loss:  0.311811
loss:  0.395982
loss:  0.293997
loss:  0.481464
loss:  0.310992
loss:  0.308922
loss:  0.290061
loss:  0.341574
loss:  0.346691
loss:  0.372554
loss:  0.259444
loss:  0.359888
loss:  0.326982
loss:  0.28865
loss:  0.294329
loss:  0.220809
loss:  0.204023
loss:  0.228559
loss:  0.333777
loss:  0.30032
loss:  0.303404
loss:  0.398202
loss:  0.298677
loss:  0.308222
loss:  0.251568
loss:  0.292305
loss:  0.262246
loss:  0.234325
loss:  0.350798
loss:  0.36277
loss:  0.304133
loss:  0.372481
loss:  0.19781
loss:  0.270574
loss:  0.25505
loss:  0.256606
loss:  0.2623
loss:  0.278689
loss:  0.273574
loss:  0.418365
loss:  0.239625
loss:  0.347957
loss:  0.339336
loss:  0.238409
loss:  0.371347
loss:  0.267659
loss:  0.300158
loss:  0.266052
loss:  0.2934
loss:  0.297358
loss:  0.242123
loss:  0.2695
loss:  0.19766
loss:  0.285037
loss:  0.297841
loss:  0.211761
loss:  0.36866
loss:  0.244272
loss:  0.30597
loss:  0.281549
loss:  0.274243
loss:  1.52577
loss:  0.261428
loss:  1.82904
loss:  0.572981
loss:  0.332454
loss:  0.298647
loss:  0.361411
loss:  0.386241
loss:  0.382936
loss:  0.330728
loss:  0.405407
loss:  0.440182
loss:  0.406172
loss:  0.622276
loss:  0.3775
loss:  0.456576
loss:  0.522239
loss:  0.529868
loss:  0.457536
loss:  0.446711
loss:  0.474233
loss:  0.357897
loss:  0.442753
loss:  0.355083
loss:  0.623408
loss:  0.413804
loss:  0.440304
loss:  0.322104
loss:  0.445629
loss:  0.408673
loss:  0.367003
loss:  0.450952
loss:  0.357315
loss:  0.518068
loss:  0.411096
epoch_i:  3
loss:  0.34713
loss:  0.450469
loss:  0.407749
loss:  0.407999
loss:  0.345674
loss:  0.441021
loss:  0.384823
loss:  0.383679
loss:  0.443795
loss:  0.490288
loss:  0.325033
loss:  0.341642
loss:  0.584043
loss:  0.438907
loss:  0.426172
loss:  0.446716
loss:  0.470373
loss:  0.374098
loss:  0.399868
loss:  0.365304
loss:  0.355068
loss:  0.333927
loss:  0.399691
loss:  0.402967
loss:  0.542589
loss:  0.355813
loss:  0.63924
loss:  0.377263
loss:  0.403375
loss:  0.456724
loss:  0.387366
loss:  0.431615
loss:  0.433727
loss:  0.325998
loss:  0.404369
loss:  0.320949
loss:  0.342653
loss:  0.279588
loss:  0.293525
loss:  0.363438
loss:  0.420193
loss:  0.268683
loss:  0.401546
loss:  0.403943
loss:  0.282363
loss:  0.36004
loss:  0.407946
loss:  0.305265
loss:  0.371451
loss:  0.370596
loss:  0.351703
loss:  0.401021
loss:  0.328069
loss:  0.425341
loss:  0.269778
loss:  0.311816
loss:  0.308522
loss:  0.373416
loss:  0.334565
loss:  0.468664
loss:  0.267671
loss:  0.457134
loss:  0.319988
loss:  0.341959
loss:  0.33549
loss:  0.374101
loss:  0.392469
loss:  0.324607
loss:  0.413446
loss:  0.411148
loss:  0.504306
loss:  0.36476
loss:  1.75112
loss:  0.431491
loss:  0.382702
loss:  0.455658
loss:  0.48967
loss:  0.459721
loss:  0.487212
loss:  0.419428
loss:  0.400987
loss:  0.379182
loss:  0.419098
loss:  0.328525
loss:  0.318565
loss:  0.390596
loss:  0.712963
loss:  0.440567
loss:  0.498415
loss:  0.477092
loss:  0.365134
loss:  0.410123
loss:  0.428484
loss:  0.4437
loss:  0.429338
loss:  0.301201
loss:  0.403771
loss:  0.34891
loss:  0.351615
loss:  0.419381
loss:  0.322344
loss:  0.428823
loss:  0.347939
loss:  0.312922
loss:  0.343434
loss:  0.306242
loss:  0.47791
loss:  0.381175
loss:  0.472761
loss:  0.345629
loss:  0.321673
loss:  0.292421
loss:  0.316027
loss:  0.326945
loss:  0.306052
loss:  0.318265
loss:  0.424608
loss:  0.261508
loss:  0.451541
loss:  0.3015
loss:  0.264114
loss:  0.304258
loss:  0.275187
loss:  0.272919
loss:  0.250567
loss:  0.307903
loss:  0.430607
loss:  0.265022
loss:  0.275657
loss:  0.310713
loss:  0.269169
loss:  0.356484
loss:  0.278809
loss:  0.42212
loss:  0.236742
loss:  0.293152
loss:  0.297235
loss:  0.265002
loss:  0.231321
loss:  0.30858
loss:  0.31498
loss:  0.236599
loss:  0.289099
loss:  0.236131
loss:  0.241589
epoch_i:  4
loss:  0.667071
loss:  0.328468
loss:  0.35918
loss:  0.308706
loss:  0.296481
loss:  0.408173
loss:  0.291252
loss:  0.358199
loss:  0.337401
loss:  0.314681
loss:  0.268887
loss:  0.279259
loss:  0.278756
loss:  0.365732
loss:  0.316325
loss:  0.243877
loss:  0.364467
loss:  0.297316
loss:  0.266618
loss:  0.35094
loss:  0.320291
loss:  0.372562
loss:  0.252235
loss:  0.252837
loss:  0.274251
loss:  0.25449
loss:  0.280894
loss:  0.272916
loss:  0.252228
loss:  0.283081
loss:  0.262415
loss:  0.256574
loss:  0.312173
loss:  0.306514
loss:  0.388646
loss:  0.236312
loss:  0.211782
loss:  0.354684
loss:  0.299997
loss:  0.369511
loss:  0.308919
loss:  0.295413
loss:  0.301978
loss:  0.526166
loss:  0.295463
loss:  0.363262
loss:  0.293383
loss:  0.326176
loss:  0.26468
loss:  0.2594
loss:  0.31506
loss:  0.387813
loss:  0.339057
loss:  0.356587
loss:  0.255165
loss:  0.275666
loss:  0.283134
loss:  0.345677
loss:  0.262195
loss:  0.255652
loss:  0.245037
loss:  0.257416
loss:  0.180963
loss:  0.291305
loss:  0.250152
loss:  0.187074
loss:  0.310328
loss:  0.237778
loss:  0.21272
loss:  0.312062
loss:  0.272496
loss:  0.323023
loss:  0.270938
loss:  0.233563
loss:  0.251376
loss:  0.383863
loss:  0.226655
loss:  0.256847
loss:  0.291693
loss:  0.3401
loss:  0.26792
loss:  0.252844
loss:  0.22408
loss:  0.236545
loss:  0.448943
loss:  0.206079
loss:  0.255253
loss:  0.30023
loss:  0.236511
loss:  0.306944
loss:  0.283311
loss:  0.294203
loss:  0.19118
loss:  0.238521
loss:  0.279057
loss:  0.273531
loss:  0.243451
loss:  0.3028
loss:  0.29013
loss:  0.252542
loss:  0.264689
loss:  0.13685
loss:  0.276503
loss:  0.272921
loss:  0.248422
loss:  0.203203
loss:  0.293462
loss:  0.241738
loss:  0.18635
loss:  0.329509
loss:  0.249524
loss:  0.210836
loss:  0.280866
loss:  0.154105
loss:  0.224124
loss:  0.191966
loss:  0.362899
loss:  0.304212
loss:  0.352267
loss:  0.239196
loss:  0.21517
loss:  0.258301
loss:  0.334746
loss:  0.312997
loss:  0.3253
loss:  0.260176
loss:  0.313387
loss:  0.283216
loss:  0.247793
loss:  0.372168
loss:  0.294055
loss:  0.244268
loss:  0.299675
loss:  0.2953
loss:  0.235154
loss:  0.269434
loss:  0.261455
loss:  0.234883
loss:  0.231404
loss:  0.252828
loss:  0.256605
loss:  0.336872
loss:  0.281343
loss:  0.255531
loss:  0.421733
epoch_i:  5
loss:  0.224981
loss:  0.217416
loss:  0.256384
loss:  0.188858
loss:  0.232416
loss:  0.197021
loss:  0.293211
loss:  0.732106
loss:  0.169438
loss:  0.365674
loss:  0.550132
loss:  0.574351
loss:  0.272164
loss:  0.32173
loss:  0.350122
loss:  0.322895
loss:  0.292475
loss:  0.322082
loss:  0.349926
loss:  0.312221
loss:  0.276082
loss:  0.287818
loss:  0.308985
loss:  0.256942
loss:  0.318962
loss:  0.503941
loss:  0.282984
loss:  0.385093
loss:  0.210933
loss:  0.281422
loss:  0.341818
loss:  0.280963
loss:  0.334006
loss:  0.303019
loss:  0.276679
loss:  0.289581
loss:  0.299048
loss:  0.349833
loss:  0.355224
loss:  0.388528
loss:  0.264668
loss:  0.235696
loss:  0.240679
loss:  0.243278
loss:  0.294538
loss:  0.269417
loss:  0.274409
loss:  0.26616
loss:  0.226591
loss:  0.239496
loss:  0.224399
loss:  0.242826
loss:  0.286718
loss:  0.237978
loss:  0.317906
loss:  0.283342
loss:  0.238194
loss:  0.205356
loss:  0.224905
loss:  0.412476
loss:  0.221212
loss:  0.240974
loss:  0.278066
loss:  0.389162
loss:  0.3299
loss:  0.313772
loss:  0.286272
loss:  0.262334
loss:  0.355562
loss:  0.272611
loss:  0.301156
loss:  0.289051
loss:  0.250471
loss:  0.340028
loss:  0.287323
loss:  0.270192
loss:  0.211992
loss:  0.225114
loss:  0.18536
loss:  0.23649
loss:  0.25134
loss:  0.334596
loss:  0.32467
loss:  0.26801
loss:  0.22492
loss:  0.193491
loss:  0.23016
loss:  0.224001
loss:  0.265416
loss:  0.261426
loss:  0.188881
loss:  0.287068
loss:  0.205878
loss:  0.26498
loss:  0.189661
loss:  0.226332
loss:  0.309738
loss:  0.417985
loss:  0.206325
loss:  0.280118
loss:  0.305698
loss:  0.276348
loss:  0.269197
loss:  0.243559
loss:  0.300854
loss:  0.245613
loss:  0.235687
loss:  0.23626
loss:  0.240518
loss:  0.286996
loss:  0.267694
loss:  0.358427
loss:  0.261499
loss:  0.228297
loss:  0.241963
loss:  0.195971
loss:  0.277616
loss:  0.23355
loss:  0.222943
loss:  0.263789
loss:  0.246604
loss:  0.188346
loss:  0.274313
loss:  0.251249
loss:  0.337166
loss:  0.200192
loss:  0.231768
loss:  0.233793
loss:  0.19836
loss:  0.346336
loss:  0.167495
loss:  0.656845
loss:  0.265576
loss:  0.346682
loss:  0.265703
loss:  0.337548
loss:  0.29807
loss:  0.187158
loss:  0.415295
loss:  0.193048
loss:  0.24216
loss:  0.296408
loss:  0.228108
loss:  0.22829
loss:  0.277536
Model saved in file: ./trained_model.ckpt
Training Finished. Saving test images to: ./runs/1510322684.8048072
